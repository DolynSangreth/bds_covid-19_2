{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d4d940e",
   "metadata": {},
   "source": [
    "# Augmentation des images des classes minoritaires \n",
    "\n",
    "<div>\n",
    "<b>Objectif:</b>\n",
    " Nous avons remarqu√© un desequilibre de nos quatres classes avec deux minoritaire et deux majoritaire (ce referer a la Data Visualisation de notre jeu de donn√©e) ce qui induisait des probl√®mes dans l'entrainement des mod√®le et donc pour les √©tapes suivante (F1_score mediocre). L'augmentation d'image √† donc √©t√© choisi comme outil pour palier au manque de donn√©es dans les classes minoritaire et pour r√©equilibrer les classes et donc le jeu de donn√©es\n",
    "</div>\n",
    "\n",
    "*Jeu de donn√©es* : [Accessible sur Kaggle](https://www.kaggle.com/datasets/tawsifurrahman/covid19-radiography-database)\n",
    "\n",
    "Apr√®s construction de la strat√©gie g√©n√©rale permettant de resoudre ce d√©s√©quilibre, plusieurs combinaisons de param√®tres ont √©t√© tester afin de determiner celle permettant l'optention des meilleurs metriques (nottament accuracy et F1-score).\n",
    "\n",
    "A not√© que la determination des valeurs des param√®tres pour l'optimisation est arbitraire et est vou√©e a vari√©e en fonction des autres √©tapes de preprocessing\n",
    "\n",
    "Pour determiner les scores des diff√©rentes preprocessing et donc la pertinance de ces derniers dans le cadre de notre jeu de donn√©e un mod√®le `Benchmark` √† √©t√© d√©velopper. Il est important de noter que celui-ci va √©volu√©e et est en aucun cas le mod√®le final.\n",
    "\n",
    "\n",
    "**Mod√®le Benchmark :**\n",
    "``` python\n",
    "\n",
    "# Charger MobileNetV2 sans la derni√®re couche (include_top=False)\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
    "base_model.trainable = False  # On ne touche pas aux poids de MobileNet\n",
    "\n",
    "# Ajouter notre classifieur (4 classes ici)\n",
    "inputs = Input(shape=(256, 256, 3))\n",
    "x = base_model(inputs, training=False)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "outputs = Dense(4, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_dataset,\n",
    "                    validation_data=val_dataset,\n",
    "                    epochs=5)\n",
    "```\n",
    "Celui ci √† √©t√© appliquer √† toutes les combinaisons de param√®tres comme indiquer dans le tableau suivant :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0126330",
   "metadata": {},
   "source": [
    "| ID | Nombre d'occurances | Nombre de couches |Valeur en argument |Bitch size |\n",
    "|:--------:|:--------:|:--------:|:--------:|:--------:|\n",
    "|1|4000 |3|0.1|32|\n",
    "|2|5000|3|0.1|32|\n",
    "|**3**|**6000**|**3**|**0.1**|**32** |\n",
    "|4|6000|2|0.1|32|\n",
    "|5|6000|3 |0.1|32|\n",
    "|6|6000|4|0.1|32|\n",
    "|7|6000|3|0.1|32|\n",
    "|8|6000|3|0.2|32|\n",
    "|9|6000|3|0.3|32|\n",
    "|10|6000|3|0.1|16|\n",
    "|11|6000|3|0.1|32|\n",
    "|12|6000|3|0.1|64|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d256d37",
   "metadata": {},
   "source": [
    "<div>\n",
    "<b>Table 1:</b>\n",
    "Combinaison de param√®tres tester pour leur optimisation\n",
    "</div>\n",
    "\n",
    "> La combinaison de param√®tre selectionn√©e correspond √† l'`ID 3`, avec un accuracy et un F1-score de 0.92. \n",
    "\n",
    "<div>\n",
    "<b>Pour allez plus loin:</b>\n",
    "Le test de l'optimisation du mod√®le benchmark a aussi √©t√© r√©alis√© sur les images avec masques en suivant le protocole optimis√© et les valeurs de accuracy et de F1-score √©taient de 0.89\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81eb3d55",
   "metadata": {},
   "source": [
    "# Augmentation d'image apr√®s optimisation des param√®tres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6803b132",
   "metadata": {},
   "source": [
    "## Chargement des packages :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da7bfe6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\grego\\anaconda3\\envs\\projet_Covid19\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importation des donn√©es \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\n",
    "import tensorflow as tf\n",
    "import pathlib\n",
    "\n",
    "#Augmentation des images \n",
    "import random\n",
    "from tensorflow.keras.layers import RandomZoom, RandomRotation, RandomContrast, Rescaling, Resizing, RandomBrightness\n",
    "\n",
    "#Modelisation\n",
    "from collections import defaultdict\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras import Input\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e21e21",
   "metadata": {},
   "source": [
    "## Chargement des diff√©rentes classes en local √† partir de dossiers : "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dc94be",
   "metadata": {},
   "source": [
    "### Pour la classe Normale : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "078a6e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10192 images charg√©es avec la forme (10192, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "# Chargement des images Normal\n",
    "folder_path = r\"C:\\Users\\grego\\OneDrive\\Bureau\\Data_Science\\Projet\\COVID-19_Radiography_Dataset\\COVID-19_Radiography_Dataset\\Normal\\images\"\n",
    "target_size = (256, 256)\n",
    "\n",
    "# Charger et convertir les images en tableau numpy\n",
    "images_normal_np = np.array([\n",
    "    img_to_array(load_img(os.path.join(folder_path, f), target_size=target_size))\n",
    "    for f in os.listdir(folder_path)\n",
    "    if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
    "])\n",
    "\n",
    "print(f\"{len(images_normal_np)} images charg√©es avec la forme {images_normal_np.shape}\")\n",
    "\n",
    "# Cr√©er un Dataset TensorFlow avec les images et les labels (0 pour Normal)\n",
    "dataset_normal = tf.data.Dataset.from_tensor_slices(\n",
    "    (images_normal_np, tf.zeros(len(images_normal_np), dtype=tf.int32))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ed2cf9",
   "metadata": {},
   "source": [
    "### Pour la classe Covid : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a66e7f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3616 images charg√©es avec la forme (3616, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "# Chargement des images COVID\n",
    "folder_path = r\"C:\\Users\\grego\\OneDrive\\Bureau\\Data_Science\\Projet\\COVID-19_Radiography_Dataset\\COVID-19_Radiography_Dataset\\COVID\\images\"\n",
    "target_size = (256, 256)\n",
    "\n",
    "# Charger et convertir les images en tableau numpy\n",
    "images_covid_np = np.array([\n",
    "    img_to_array(load_img(os.path.join(folder_path, f), target_size=target_size))\n",
    "    for f in os.listdir(folder_path)\n",
    "    if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
    "])\n",
    "\n",
    "print(f\"{len(images_covid_np)} images charg√©es avec la forme {images_covid_np.shape}\")\n",
    "\n",
    "# Cr√©er un Dataset TensorFlow avec les images et les labels (1 pour COVID)\n",
    "dataset_covid = tf.data.Dataset.from_tensor_slices(\n",
    "    (images_covid_np, tf.ones(len(images_covid_np), dtype=tf.int32))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75c0e7c",
   "metadata": {},
   "source": [
    "### Pour la classe Lung Opacity : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4215797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6012 images charg√©es avec la forme (6012, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "# Chargement des images Lung Opacity\n",
    "folder_path = r\"C:\\Users\\grego\\OneDrive\\Bureau\\Data_Science\\Projet\\COVID-19_Radiography_Dataset\\COVID-19_Radiography_Dataset\\Lung_opacity\\images\"\n",
    "target_size = (256, 256)\n",
    "\n",
    "# Charger et convertir les images en tableau numpy\n",
    "images_opacity_np = np.array([\n",
    "    img_to_array(load_img(os.path.join(folder_path, f), target_size=target_size))\n",
    "    for f in os.listdir(folder_path)\n",
    "    if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
    "])\n",
    "\n",
    "print(f\"{len(images_opacity_np)} images charg√©es avec la forme {images_opacity_np.shape}\")\n",
    "\n",
    "# Cr√©er un Dataset TensorFlow avec les images et les labels (2 pour Lung_opacity)\n",
    "dataset_opacity = tf.data.Dataset.from_tensor_slices(\n",
    "    (images_opacity_np, tf.fill(len(images_opacity_np), tf.constant(2, dtype=tf.int32))\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fcdb74",
   "metadata": {},
   "source": [
    "### Pour la classe Viral Pneumonia : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f421144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1345 images charg√©es avec la forme (1345, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "# Chargement des images Viral Pneumonia\n",
    "folder_path = r\"C:\\Users\\grego\\OneDrive\\Bureau\\Data_Science\\Projet\\COVID-19_Radiography_Dataset\\COVID-19_Radiography_Dataset\\Viral_Pneumonia\\images\"\n",
    "target_size = (256, 256)\n",
    "\n",
    "# Charger et convertir les images en tableau numpy\n",
    "images_pneumonia_np = np.array([\n",
    "    img_to_array(load_img(os.path.join(folder_path, f), target_size=target_size))\n",
    "    for f in os.listdir(folder_path)\n",
    "    if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
    "])\n",
    "\n",
    "print(f\"{len(images_pneumonia_np)} images charg√©es avec la forme {images_pneumonia_np.shape}\")\n",
    "\n",
    "# Cr√©er un Dataset TensorFlow avec les images et les labels (3 pour Viral Pneumonia)\n",
    "dataset_pneumonia = tf.data.Dataset.from_tensor_slices(\n",
    "    (images_pneumonia_np, tf.fill(len(images_pneumonia_np), tf.constant(2, dtype=tf.int32))\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a31aeb",
   "metadata": {},
   "source": [
    "## Preprocessing/Augmentation d'images : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61d355ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\grego\\anaconda3\\envs\\projet_Covid19\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "Classe 1 : 3616 images\n",
      " ‚ûï G√©n√©ration de 2384 images pour la classe 1\n",
      "Classe 3 : 1345 images\n",
      " ‚ûï G√©n√©ration de 4655 images pour la classe 3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ‚öôÔ∏è Param√®tres\n",
    "target_per_class = 6000\n",
    "random.seed(42)\n",
    "\n",
    "# üîß Couches d'augmentation\n",
    "random_zoom = RandomZoom(0.1)\n",
    "random_rotation = RandomRotation(0.1)\n",
    "random_contrast = RandomContrast(0.1)\n",
    "rescale = Rescaling(1./255)\n",
    "resize = Resizing(256, 256)  # ‚¨ÖÔ∏è Adapt√© √† MobileNetV2\n",
    "\n",
    "augmentations = [random_zoom, random_rotation, random_contrast, resize, rescale]\n",
    "\n",
    "# üîÑ Fonction d'augmentation\n",
    "def augment_image(image, augmentations):\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    for aug_fn in augmentations:\n",
    "        image = aug_fn(image)\n",
    "    return image\n",
    "\n",
    "\n",
    "# üì¶ Augmentation par classe\n",
    "def augmenter_dataset_monoclasse(dataset, label, target, augmentations):\n",
    "    dataset_list = list(dataset)\n",
    "    images = [img for img, _ in dataset_list]\n",
    "    labels = [label] * len(images)\n",
    "\n",
    "    count = len(images)\n",
    "    print(f\"Classe {label} : {count} images\")\n",
    "\n",
    "    if count > target:\n",
    "        print(f\" ‚úÇÔ∏è R√©duction √† {target} images pour la classe {label}\")\n",
    "        images = images[:target]\n",
    "        labels = [label] * target\n",
    "\n",
    "    if count < target:\n",
    "        to_generate = target - count\n",
    "        print(f\" ‚ûï G√©n√©ration de {to_generate} images pour la classe {label}\")\n",
    "        for _ in range(to_generate):\n",
    "            img = images[random.randint(0, count - 1)]\n",
    "            aug_img = augment_image(img, augmentations)\n",
    "            images.append(aug_img)\n",
    "            labels.append(label)\n",
    "\n",
    "    return tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "\n",
    "# üß™ Appliquer l‚Äôaugmentation individuellement\n",
    "dataset_covid     = augmenter_dataset_monoclasse(dataset_covid,     label=1, target=target_per_class, augmentations=augmentations)\n",
    "dataset_pneumonia = augmenter_dataset_monoclasse(dataset_pneumonia, label=3, target=target_per_class, augmentations=augmentations)\n",
    "dataset_opacity = dataset_opacity.take(6000)\n",
    "dataset_normal = dataset_normal.take(6000)\n",
    "\n",
    "# ‚úÖ Dataset complet √©quilibr√©\n",
    "full_dataset = dataset_covid.concatenate(dataset_pneumonia)\\\n",
    "                               .concatenate(dataset_normal)\\\n",
    "                               .concatenate(dataset_opacity)\n",
    "\n",
    "full_dataset_list = list(full_dataset)\n",
    "images, labels = zip(*full_dataset_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87260296",
   "metadata": {},
   "source": [
    "## Mise en forme pr√©-entrainement : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23043da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Labels du batch train :  [1 3 1 3 2 3 2 3 2 0 2 2 3 1 3 3 3 0 3 2 3 3 3 0 0 3 1 1 1 3 2 3]\n",
      "‚úÖ Labels du batch val :  [2 3 3 3 0 1 1 3 1 3 0 3 1 3 0 1 1 0 3 1 3 3 3 2 0 3 0 1 1 2 3 0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Assurer que labels sont des ints hashables\n",
    "clean_labels = [int(label.numpy()) if isinstance(label, tf.Tensor) else int(label) for label in labels]\n",
    "\n",
    "# Split STRATIFI√â (permet d'√©quilibr√©e train et validation)\n",
    "images_by_class = defaultdict(list)\n",
    "for img, label in zip(images, clean_labels):\n",
    "    images_by_class[label].append(img)\n",
    "\n",
    "train_images, train_labels = [], []\n",
    "val_images, val_labels = [], []\n",
    "\n",
    "for label, imgs in images_by_class.items():\n",
    "    split_idx = int(0.8 * len(imgs))\n",
    "    train_images += imgs[:split_idx]\n",
    "    train_labels += [label] * split_idx\n",
    "    val_images += imgs[split_idx:]\n",
    "    val_labels += [label] * (len(imgs) - split_idx)\n",
    "\n",
    "# M√©lange avec s√©curit√©\n",
    "combined_train = list(zip(train_images, train_labels))\n",
    "combined_val = list(zip(val_images, val_labels))\n",
    "random.shuffle(combined_train)\n",
    "random.shuffle(combined_val)\n",
    "\n",
    "if combined_train:\n",
    "    train_images, train_labels = zip(*combined_train)\n",
    "else:\n",
    "    train_images, train_labels = [], []\n",
    "\n",
    "if combined_val:\n",
    "    val_images, val_labels = zip(*combined_val)\n",
    "else:\n",
    "    val_images, val_labels = [], []\n",
    "\n",
    "# G√©n√©rateurs robustes\n",
    "def generator_train():\n",
    "    for img, label in zip(train_images, train_labels):\n",
    "        yield tf.convert_to_tensor(img, dtype=tf.float32), tf.convert_to_tensor(label, dtype=tf.int32)\n",
    "\n",
    "def generator_val():\n",
    "    for img, label in zip(val_images, val_labels):\n",
    "        yield tf.convert_to_tensor(img, dtype=tf.float32), tf.convert_to_tensor(label, dtype=tf.int32)\n",
    "\n",
    "# D√©finition de l'output signature pour correspondres a nos attentes \n",
    "output_signature = (\n",
    "    tf.TensorSpec(shape=(256, 256, 3), dtype=tf.float32),\n",
    "    tf.TensorSpec(shape=(), dtype=tf.int32)\n",
    ")\n",
    "\n",
    "# Construction des datasets\n",
    "train_dataset = tf.data.Dataset.from_generator(generator_train, output_signature=output_signature)\n",
    "val_dataset = tf.data.Dataset.from_generator(generator_val, output_signature=output_signature)\n",
    "\n",
    "BATCH_SIZE = 32 # param√®tre optimiser \n",
    "train_dataset = train_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# V√©rification de la stratification\n",
    "for _, labels_batch in train_dataset.take(1):\n",
    "    print(\"‚úÖ Labels du batch train : \", labels_batch.numpy())\n",
    "for _, labels_batch in val_dataset.take(1):\n",
    "    print(\"‚úÖ Labels du batch val : \", labels_batch.numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3f9b42",
   "metadata": {},
   "source": [
    "## Creation et instance du mod√®le benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d2c2b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\grego\\anaconda3\\envs\\projet_Covid19\\lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Charger MobileNetV2 sans la derni√®re couche (include_top=False)\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
    "base_model.trainable = False  # On ne touche pas aux poids de MobileNet\n",
    "\n",
    "# Ajouter notre classifieur (4 classes ici)\n",
    "inputs = Input(shape=(256, 256, 3))\n",
    "x = base_model(inputs, training=False)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "outputs = Dense(4, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b703786d",
   "metadata": {},
   "source": [
    "## Entrainement du mod√®le :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e7f3ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\grego\\anaconda3\\envs\\projet_Covid19\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:From c:\\Users\\grego\\anaconda3\\envs\\projet_Covid19\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\grego\\anaconda3\\envs\\projet_Covid19\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "600/600 [==============================] - 315s 517ms/step - loss: 0.6912 - accuracy: 0.7136 - val_loss: 0.3019 - val_accuracy: 0.8921\n",
      "Epoch 2/5\n",
      "600/600 [==============================] - ETA: 0s - loss: 0.5312 - accuracy: 0.7881"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_dataset,\n",
    "                    validation_data=val_dataset,\n",
    "                    epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578479f8",
   "metadata": {},
   "source": [
    "# Metriques : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a8f9c32",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for batch_x, batch_y in val_dataset:\n",
    "    preds = model.predict(batch_x)\n",
    "    y_pred.extend(np.argmax(preds, axis=1))  # pr√©dictions argmax\n",
    "    y_true.extend(batch_y.numpy())  # convertir les labels en numpy\n",
    "\n",
    "# Optionnel : cast en array\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "# Rapport\n",
    "print(classification_report(y_true, y_pred))\n",
    "\n",
    "# Matrice de confusion\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d')\n",
    "plt.xlabel('Pr√©dit')\n",
    "plt.ylabel('R√©el')\n",
    "plt.title('Matrice de confusion')\n",
    "plt.show()\n",
    "\n",
    "# F1-scores\n",
    "f1_macro = f1_score(y_true, y_pred, average='macro')\n",
    "f1_weighted = f1_score(y_true, y_pred, average='weighted')\n",
    "print(f\"F1 macro     : {f1_macro:.4f}\")\n",
    "print(f\"F1 weighted  : {f1_weighted:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projet_Covid19",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
